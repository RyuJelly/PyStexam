{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[8]\") \\\n",
    "                    .appName('sparkedu') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "text() got an unexpected keyword argument 'converters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0835308417c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mast\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mliteral_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output/(수정)최종레시피1.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'ingredient'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mliteral_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seasoning'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mliteral_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'howto'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mliteral_eval\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: text() got an unexpected keyword argument 'converters'"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "rdd = spark.read.text(\"output/(수정)최종레시피1.csv\", converters={'ingredient' : literal_eval, 'seasoning' : literal_eval, 'howto' : literal_eval})\n",
    "print(type(rdd))\n",
    "print(rdd.collect()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS-LINUX\n",
    "\n",
    "import findspark\n",
    "findspark.init(\"/opt/spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-43-117.ap-northeast-2.compute.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sparkedu</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe19c5fb128>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelCollectionRDD[3] at readRDDFromFile at PythonRDD.scala:262\n",
      "<class 'pyspark.rdd.RDD'>\n",
      "[('Java', 20000), ('Python', 100000), ('Scala', 3000)]\n"
     ]
    }
   ],
   "source": [
    "dataList = [(\"Java\", 20000), (\"Python\", 100000), (\"Scala\", 3000)]\n",
    "rdd=spark.sparkContext.parallelize(dataList)\n",
    "print(rdd)\n",
    "print(type(rdd))\n",
    "print(rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.1\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_df = spark.read.csv(\"output/recipe.csv\",header = 'True',inferSchema='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers_count = recipe_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91739\n"
     ]
    }
   ],
   "source": [
    "print(passengers_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+--------------------------+---------------------------------+--------------------------+--------------------------------+-----------------------------+----------+\n",
      "|                              name|                ingredient|                  ingredient_name|                 seasoning|                  seasoning_name|                        howto|recipe_num|\n",
      "+----------------------------------+--------------------------+---------------------------------+--------------------------+--------------------------------+-----------------------------+----------+\n",
      "|손쉽게 만드는 소불고기덮밥 레시...|  ['소불고기', '200g', ...|               소불고기 양파 대파| ['간장', '4스푼', '물o...|   간장 다진마늘 올리고당 참기름|['1. 양파와 대파는 미리 썰...|   6947317|\n",
      "|   사과를 활용한 요리 / 프랑스 ...| ['계란', '1개', '설탕'...|계란 설탕 우유 생크림 찹쌀가루...|                        []|                            null|  ['1. 볼에 계란, 설탕, 우...|   6947316|\n",
      "|  사과를 활용한 요리 / 사과 겉절이|['사과', '1개', '고춧가...| 사과 고춧가루 액젓 매실액 레몬즙|                        []|                            null|['1. 사과는 씻어 준비한다....|   6947315|\n",
      "|              # 당면활용, 당면만두|   ['당면', '120g', '계...|당면 계란 간장 튀김가루 홍고추...|['간장', '1스푼', '식초...|간장 식초 물 레몬즙 고추가루 ...|['1. 끓는 물에 당면을 삶아...|   6947314|\n",
      "| 보들한 무청이 더 맛있는 코다리...|['코다리', '3마리', '무...|코다리 무청 간장 청주 고춧가루...|                        []|                            null|['1. 코다리 3마리를 준비해...|   6947313|\n",
      "+----------------------------------+--------------------------+---------------------------------+--------------------------+--------------------------------+-----------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recipe_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.column.Column'>\n"
     ]
    }
   ],
   "source": [
    "print(type(recipe_df[\"seasoning\"][2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awsvenv",
   "language": "python",
   "name": "awsvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
